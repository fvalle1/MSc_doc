\section{Component systems}
\begin{figure}[htb!]
\centering
\begin{tabular}{cc}
&Realizations\\
 \rotatebox[origin=c]{90}{Components}&
  $\left(\begin{array}{ccccc}{n_{11}} & {n_{12}} & {n_{13}} & {\dots} & {n_{1 R}} \\ {n_{2 1}} & {n_{2 2}} & {n_{2 3}} & {\dots} & {n_{2 R}} \\ {\vdots} & {\vdots} & {\vdots} & {\ddots} & {\vdots} \\ {n_{N 1}} & {n_{N 2}} & {n_{N 3}} & {\dots} & {n_{N R}}\end{array}\right)$\\
\end{tabular}
\caption{Structure of a matrix representing component systems with $i=0\dots N$ rows and $j=0\dots R$ columns}
\label{fig:componetstable}
\end{figure}
The most common example of such systems is a set of books, in this case one puts 
on the rows the words in the whole vocabulary and the books' titles on the columns; 
the entry that correspond to row $i$ and column $j$ is the number of times the word $i$
appears in book $j$. The same happens if one considers Wikipedia's pages.
Other examples are Lego$\textsuperscript{\textregistered}$ sets where components are the Lego$\textsuperscript{\textregistered}$ bricks and realizations Lego$\textsuperscript{\textregistered}$ packages and protein domains; all these were described and well studied in~\cite{mazzolini2018heaps}.

Given a matrix with $N$ components on the rows and $R$ realizations on the columns and relative abundances $n_{ij}$ as the entries, it is interesting to study some quantities
that are universal and general characteristics of component systems.

First of all, the \textbf{occurrence} of a component, defined as 
\begin{equation}\label{eq:occurrence}
o_i=\frac{\sum_{j=1}^{R}(1-\delta_{n_{ij},0})}{R},
\end{equation}
is the number of realizations in which the component's abundance is not null.
A component that is present in all the realizations has got $O_i=1$.
Components with high ($\simeq 1$) occurrence are present in mostly all realisations of the datasets, in linguistics this components are articles.
Components with low occurrence $\simeq 0$ are present only in a few realisations 
and are the most specific ones.

The sum across all columns is called \textbf{abundance} of a component and is defined as:
\begin{equation}\label{eq:abundance}
a_i=\sum_{j=1}^{R}n_{ij};
\end{equation}
dividing this by the global abundance 
\begin{equation}
  a=\sum_{i=1}^{N}a_i
\end{equation}
naturally brings to the \textbf{frequency of a component} in the whole corpus
\begin{equation}\label{eq:fi}
f_i=\frac{a_i}{\sum_{c=1}^{N}a_{c}}.
\end{equation}

Dividing the abundance of a component by the sum of all abundances in a realisation
 gives the frequency of the component in that specific realization 
\begin{equation}
f_{ij}=\frac{n_{ij}}{\sum_{c=1}^{N}n_{cj}}.
\end{equation}

The sum of all abundances in the same realization
\begin{equation}\label{eq:size}
M_j=\sum_{c=1}^{N}n_{cj}
\end{equation}
is called \textbf{size}.

It is expected that frequencies distribute according to the so called Zipf's law
\begin{equation}\label{eq:zipf}
f_i\propto r_i^{-\alpha}
\end{equation}
where $r$ is the rank: the position of a component when sorting all components
by their frequencies in the whole dataset.